{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "shADrZ_kWJe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bca38ca4-6bce-46ea-843a-dfe26112e60d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/RUSTEYE/dataset_cnn_v2.zip"
      ],
      "metadata": {
        "id": "h4sBLblm9z-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k3GbZIAzUqPh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 80"
      ],
      "metadata": {
        "id": "FvFKwzZ_Uyz6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/dataset_cnn_v2/train'\n",
        "val_dir   = '/content/dataset_cnn_v2/valid'\n",
        "test_dir = '/content/dataset_cnn_v2/test'\n",
        "\n",
        "# Data augmentation cho train\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Train generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Validation generator\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Test generator\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "g7DqWMXJU4MM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "460ad36e-9220-4e7c-b485-7ac9520279d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 945 images belonging to 4 classes.\n",
            "Found 202 images belonging to 4 classes.\n",
            "Found 205 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Thêm các layer phía trên\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "C8-LD-FWU8ST",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "740be4d8-1b5b-4c36-fff2-1bcc8799048d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "_AS9a9h-VFTU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min', restore_best_weights=True)"
      ],
      "metadata": {
        "id": "xQCN6HYCVLlx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "5X7pIPN1VYCl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bed6b03b-d507-4b1b-d0b3-b5347b1893be"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 1s/step - accuracy: 0.3331 - loss: 1.8100 - val_accuracy: 0.4059 - val_loss: 1.3702\n",
            "Epoch 2/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 706ms/step - accuracy: 0.4131 - loss: 1.2402 - val_accuracy: 0.5347 - val_loss: 1.0801\n",
            "Epoch 3/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 725ms/step - accuracy: 0.4884 - loss: 1.1028 - val_accuracy: 0.5347 - val_loss: 0.9752\n",
            "Epoch 4/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 656ms/step - accuracy: 0.5425 - loss: 1.0296 - val_accuracy: 0.5050 - val_loss: 1.0245\n",
            "Epoch 5/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 730ms/step - accuracy: 0.5000 - loss: 1.0546 - val_accuracy: 0.5941 - val_loss: 0.8942\n",
            "Epoch 6/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 694ms/step - accuracy: 0.5496 - loss: 0.9496 - val_accuracy: 0.5644 - val_loss: 0.8658\n",
            "Epoch 7/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 709ms/step - accuracy: 0.5559 - loss: 0.9868 - val_accuracy: 0.5248 - val_loss: 0.9404\n",
            "Epoch 8/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 661ms/step - accuracy: 0.5676 - loss: 0.9233 - val_accuracy: 0.6089 - val_loss: 0.8708\n",
            "Epoch 9/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 708ms/step - accuracy: 0.5634 - loss: 0.9663 - val_accuracy: 0.6040 - val_loss: 0.8818\n",
            "Epoch 10/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 694ms/step - accuracy: 0.5597 - loss: 0.9251 - val_accuracy: 0.6386 - val_loss: 0.8176\n",
            "Epoch 11/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 754ms/step - accuracy: 0.5855 - loss: 0.8911 - val_accuracy: 0.6634 - val_loss: 0.7959\n",
            "Epoch 12/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 661ms/step - accuracy: 0.5889 - loss: 0.8562 - val_accuracy: 0.6287 - val_loss: 0.8330\n",
            "Epoch 13/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 682ms/step - accuracy: 0.5963 - loss: 0.8761 - val_accuracy: 0.6287 - val_loss: 0.8440\n",
            "Epoch 14/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 666ms/step - accuracy: 0.6393 - loss: 0.8369 - val_accuracy: 0.6238 - val_loss: 0.8125\n",
            "Epoch 15/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 755ms/step - accuracy: 0.5980 - loss: 0.8525 - val_accuracy: 0.6485 - val_loss: 0.7823\n",
            "Epoch 16/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 697ms/step - accuracy: 0.5994 - loss: 0.8632 - val_accuracy: 0.6733 - val_loss: 0.7612\n",
            "Epoch 17/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 701ms/step - accuracy: 0.6335 - loss: 0.8059 - val_accuracy: 0.6436 - val_loss: 0.7727\n",
            "Epoch 18/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 723ms/step - accuracy: 0.6344 - loss: 0.8109 - val_accuracy: 0.6782 - val_loss: 0.7571\n",
            "Epoch 19/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 680ms/step - accuracy: 0.6264 - loss: 0.7969 - val_accuracy: 0.5891 - val_loss: 0.8874\n",
            "Epoch 20/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 677ms/step - accuracy: 0.6522 - loss: 0.7800 - val_accuracy: 0.6733 - val_loss: 0.7514\n",
            "Epoch 21/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 727ms/step - accuracy: 0.6395 - loss: 0.7982 - val_accuracy: 0.6980 - val_loss: 0.7338\n",
            "Epoch 22/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 667ms/step - accuracy: 0.6411 - loss: 0.7838 - val_accuracy: 0.6782 - val_loss: 0.7300\n",
            "Epoch 23/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 737ms/step - accuracy: 0.6509 - loss: 0.7618 - val_accuracy: 0.6634 - val_loss: 0.7335\n",
            "Epoch 24/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 671ms/step - accuracy: 0.6086 - loss: 0.7994 - val_accuracy: 0.6485 - val_loss: 0.7895\n",
            "Epoch 25/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 702ms/step - accuracy: 0.6578 - loss: 0.7902 - val_accuracy: 0.6931 - val_loss: 0.7021\n",
            "Epoch 26/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 693ms/step - accuracy: 0.6720 - loss: 0.7741 - val_accuracy: 0.6980 - val_loss: 0.6955\n",
            "Epoch 27/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 726ms/step - accuracy: 0.6418 - loss: 0.7939 - val_accuracy: 0.7030 - val_loss: 0.6899\n",
            "Epoch 28/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 662ms/step - accuracy: 0.6944 - loss: 0.7270 - val_accuracy: 0.5743 - val_loss: 0.8401\n",
            "Epoch 29/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 682ms/step - accuracy: 0.6061 - loss: 0.8508 - val_accuracy: 0.6634 - val_loss: 0.7321\n",
            "Epoch 30/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 684ms/step - accuracy: 0.6571 - loss: 0.7467 - val_accuracy: 0.5990 - val_loss: 0.8011\n",
            "Epoch 31/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 710ms/step - accuracy: 0.6918 - loss: 0.7293 - val_accuracy: 0.6634 - val_loss: 0.7574\n",
            "Epoch 32/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 689ms/step - accuracy: 0.6598 - loss: 0.7431 - val_accuracy: 0.6733 - val_loss: 0.6995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best model\n",
        "from tensorflow.keras.models import load_model\n",
        "best_model = load_model('best_model.keras')"
      ],
      "metadata": {
        "id": "PnARkl93K11I"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Đánh giá trên test set\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "test_loss, test_accuracy = best_model.evaluate(test_generator)\n",
        "print(f'\\nTest Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
        "\n",
        "# Lấy nhãn class\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "predictions = best_model.predict(test_generator)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = test_generator.classes\n",
        "\n",
        "# Metrics\n",
        "accuracy = accuracy_score(true_classes, predicted_classes)\n",
        "precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
        "recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
        "f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
        "\n",
        "print('Accuracy:', accuracy * 100)\n",
        "print('Precision:', precision * 100)\n",
        "print('Recall:', recall * 100)\n",
        "print('F1 Score:', f1* 100)\n",
        "\n",
        "print('\\nClassification Report:')\n",
        "print(classification_report(true_classes, predicted_classes, target_names=class_labels, digits=4))\n",
        "\n",
        "# Accuracy theo từng class\n",
        "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
        "\n",
        "print('\\nAccuracy for each class:')\n",
        "for class_name, class_accuracy in zip(class_labels, class_accuracies):\n",
        "    print(f'{class_name}: {class_accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RC2db3Dvuso",
        "outputId": "11891567-40f2-4624-f612-56de1bc8bb43"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 718ms/step - accuracy: 0.5925 - loss: 0.8352\n",
            "\n",
            "Test Loss: 0.6879\n",
            "Test Accuracy: 70.73%\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 775ms/step\n",
            "Accuracy: 70.73170731707317\n",
            "Precision: 70.51864500566309\n",
            "Recall: 70.73170731707317\n",
            "F1 Score: 69.23904566532259\n",
            "\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            " bong-troc-son     0.6786    0.3725    0.4810        51\n",
            "day-cap-ri-set     0.6615    0.7544    0.7049        57\n",
            "        ri-set     0.6452    0.7692    0.7018        52\n",
            "       vet-nut     0.8600    0.9556    0.9053        45\n",
            "\n",
            "      accuracy                         0.7073       205\n",
            "     macro avg     0.7113    0.7129    0.6982       205\n",
            "  weighted avg     0.7052    0.7073    0.6924       205\n",
            "\n",
            "\n",
            "Accuracy for each class:\n",
            "bong-troc-son: 0.37\n",
            "day-cap-ri-set: 0.75\n",
            "ri-set: 0.77\n",
            "vet-nut: 0.96\n"
          ]
        }
      ]
    }
  ]
}