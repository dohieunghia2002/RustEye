{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "shADrZ_kWJe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bca38ca4-6bce-46ea-843a-dfe26112e60d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/RUSTEYE/dataset_cnn_v2.zip"
      ],
      "metadata": {
        "id": "h4sBLblm9z-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k3GbZIAzUqPh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 80"
      ],
      "metadata": {
        "id": "FvFKwzZ_Uyz6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/dataset_cnn_v2/train'\n",
        "val_dir   = '/content/dataset_cnn_v2/valid'\n",
        "test_dir = '/content/dataset_cnn_v2/test'\n",
        "\n",
        "# Data augmentation cho train\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Train generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Validation generator\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Test generator\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "g7DqWMXJU4MM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86af0ba9-1a4c-4c66-e798-5c083ade3454"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 945 images belonging to 4 classes.\n",
            "Found 202 images belonging to 4 classes.\n",
            "Found 205 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Thêm các layer phía trên\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "C8-LD-FWU8ST",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d168585-bf40-4c67-bd42-370703176e8b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "_AS9a9h-VFTU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min', restore_best_weights=True)"
      ],
      "metadata": {
        "id": "xQCN6HYCVLlx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "5X7pIPN1VYCl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5520199-ed16-4807-fb93-82a88eefd3bf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - accuracy: 0.4925 - loss: 2.6518 - val_accuracy: 0.8317 - val_loss: 0.3495\n",
            "Epoch 2/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 738ms/step - accuracy: 0.8660 - loss: 0.3488 - val_accuracy: 0.8515 - val_loss: 0.3432\n",
            "Epoch 3/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 733ms/step - accuracy: 0.8659 - loss: 0.3204 - val_accuracy: 0.9158 - val_loss: 0.2324\n",
            "Epoch 4/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 765ms/step - accuracy: 0.8605 - loss: 0.3676 - val_accuracy: 0.8713 - val_loss: 0.3171\n",
            "Epoch 5/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 715ms/step - accuracy: 0.9069 - loss: 0.2305 - val_accuracy: 0.9257 - val_loss: 0.2056\n",
            "Epoch 6/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 702ms/step - accuracy: 0.9209 - loss: 0.2067 - val_accuracy: 0.8861 - val_loss: 0.3202\n",
            "Epoch 7/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 732ms/step - accuracy: 0.9073 - loss: 0.2432 - val_accuracy: 0.9208 - val_loss: 0.1845\n",
            "Epoch 8/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 743ms/step - accuracy: 0.9311 - loss: 0.1886 - val_accuracy: 0.9406 - val_loss: 0.1726\n",
            "Epoch 9/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 712ms/step - accuracy: 0.9486 - loss: 0.1370 - val_accuracy: 0.9505 - val_loss: 0.1522\n",
            "Epoch 10/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 708ms/step - accuracy: 0.9618 - loss: 0.1123 - val_accuracy: 0.9307 - val_loss: 0.2077\n",
            "Epoch 11/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 683ms/step - accuracy: 0.8863 - loss: 0.2912 - val_accuracy: 0.9059 - val_loss: 0.2388\n",
            "Epoch 12/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 757ms/step - accuracy: 0.8984 - loss: 0.2351 - val_accuracy: 0.9604 - val_loss: 0.1458\n",
            "Epoch 13/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 696ms/step - accuracy: 0.9325 - loss: 0.1831 - val_accuracy: 0.9406 - val_loss: 0.1637\n",
            "Epoch 14/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 677ms/step - accuracy: 0.9520 - loss: 0.1371 - val_accuracy: 0.9455 - val_loss: 0.1835\n",
            "Epoch 15/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 694ms/step - accuracy: 0.9461 - loss: 0.1342 - val_accuracy: 0.9208 - val_loss: 0.2125\n",
            "Epoch 16/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 655ms/step - accuracy: 0.9327 - loss: 0.1477 - val_accuracy: 0.9505 - val_loss: 0.1716\n",
            "Epoch 17/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 729ms/step - accuracy: 0.9545 - loss: 0.1282 - val_accuracy: 0.9554 - val_loss: 0.1382\n",
            "Epoch 18/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 652ms/step - accuracy: 0.9544 - loss: 0.1229 - val_accuracy: 0.9307 - val_loss: 0.1808\n",
            "Epoch 19/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 668ms/step - accuracy: 0.9647 - loss: 0.1137 - val_accuracy: 0.9604 - val_loss: 0.1407\n",
            "Epoch 20/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 683ms/step - accuracy: 0.9512 - loss: 0.1190 - val_accuracy: 0.9010 - val_loss: 0.2604\n",
            "Epoch 21/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 678ms/step - accuracy: 0.9365 - loss: 0.1542 - val_accuracy: 0.9505 - val_loss: 0.1654\n",
            "Epoch 22/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 751ms/step - accuracy: 0.9573 - loss: 0.0943 - val_accuracy: 0.9505 - val_loss: 0.1527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best model\n",
        "from tensorflow.keras.models import load_model\n",
        "best_model = load_model('best_model.keras')"
      ],
      "metadata": {
        "id": "PnARkl93K11I"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Đánh giá trên test set\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "test_loss, test_accuracy = best_model.evaluate(test_generator)\n",
        "print(f'\\nTest Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
        "\n",
        "# Lấy nhãn class\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "predictions = best_model.predict(test_generator)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = test_generator.classes\n",
        "\n",
        "# Metrics\n",
        "accuracy = accuracy_score(true_classes, predicted_classes)\n",
        "precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
        "recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
        "f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
        "\n",
        "print('Accuracy:', accuracy * 100)\n",
        "print('Precision:', precision * 100)\n",
        "print('Recall:', recall * 100)\n",
        "print('F1 Score:', f1* 100)\n",
        "\n",
        "print('\\nClassification Report:')\n",
        "print(classification_report(true_classes, predicted_classes, target_names=class_labels, digits=4))\n",
        "\n",
        "# Accuracy theo từng class\n",
        "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
        "\n",
        "print('\\nAccuracy for each class:')\n",
        "for class_name, class_accuracy in zip(class_labels, class_accuracies):\n",
        "    print(f'{class_name}: {class_accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RC2db3Dvuso",
        "outputId": "774b4a3f-3fc4-4c6b-97f4-f7e63d867394"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.9486 - loss: 0.1624\n",
            "\n",
            "Test Loss: 0.1814\n",
            "Test Accuracy: 93.17%\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step\n",
            "Accuracy: 93.17073170731707\n",
            "Precision: 93.97322631777747\n",
            "Recall: 93.17073170731707\n",
            "F1 Score: 93.20253727638669\n",
            "\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            " bong-troc-son     0.8226    1.0000    0.9027        51\n",
            "day-cap-ri-set     0.9623    0.8947    0.9273        57\n",
            "        ri-set     0.9778    0.8462    0.9072        52\n",
            "       vet-nut     1.0000    1.0000    1.0000        45\n",
            "\n",
            "      accuracy                         0.9317       205\n",
            "     macro avg     0.9407    0.9352    0.9343       205\n",
            "  weighted avg     0.9397    0.9317    0.9320       205\n",
            "\n",
            "\n",
            "Accuracy for each class:\n",
            "bong-troc-son: 1.00\n",
            "day-cap-ri-set: 0.89\n",
            "ri-set: 0.85\n",
            "vet-nut: 1.00\n"
          ]
        }
      ]
    }
  ]
}