{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "shADrZ_kWJe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bca38ca4-6bce-46ea-843a-dfe26112e60d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/RUSTEYE/dataset_cnn_v2.zip"
      ],
      "metadata": {
        "id": "h4sBLblm9z-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "k3GbZIAzUqPh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 80"
      ],
      "metadata": {
        "id": "FvFKwzZ_Uyz6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/dataset_cnn_v2/train'\n",
        "val_dir   = '/content/dataset_cnn_v2/valid'\n",
        "test_dir = '/content/dataset_cnn_v2/test'\n",
        "\n",
        "# Data augmentation cho train\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Train generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Validation generator\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Test generator\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "g7DqWMXJU4MM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e133b07-e21d-4403-a019-2468f32781b8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 945 images belonging to 4 classes.\n",
            "Found 202 images belonging to 4 classes.\n",
            "Found 205 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Base model DenseNet121\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Thêm các layer phía trên\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "C8-LD-FWU8ST",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "284be092-1ce7-45fe-faea-040380df1e3f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "_AS9a9h-VFTU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min', restore_best_weights=True)"
      ],
      "metadata": {
        "id": "xQCN6HYCVLlx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "5X7pIPN1VYCl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ac9760c-4ade-483a-fb64-de82341727de"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.5963 - loss: 1.0687 - val_accuracy: 0.8861 - val_loss: 0.3011\n",
            "Epoch 2/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 756ms/step - accuracy: 0.9182 - loss: 0.2298 - val_accuracy: 0.9356 - val_loss: 0.2248\n",
            "Epoch 3/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 743ms/step - accuracy: 0.9475 - loss: 0.1441 - val_accuracy: 0.9455 - val_loss: 0.1447\n",
            "Epoch 4/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 714ms/step - accuracy: 0.9628 - loss: 0.1148 - val_accuracy: 0.9505 - val_loss: 0.1427\n",
            "Epoch 5/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 702ms/step - accuracy: 0.9606 - loss: 0.1242 - val_accuracy: 0.9455 - val_loss: 0.2301\n",
            "Epoch 6/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 659ms/step - accuracy: 0.9468 - loss: 0.1434 - val_accuracy: 0.9604 - val_loss: 0.1498\n",
            "Epoch 7/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 701ms/step - accuracy: 0.9702 - loss: 0.1057 - val_accuracy: 0.9406 - val_loss: 0.1511\n",
            "Epoch 8/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 724ms/step - accuracy: 0.9701 - loss: 0.0891 - val_accuracy: 0.9406 - val_loss: 0.1893\n",
            "Epoch 9/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 740ms/step - accuracy: 0.9658 - loss: 0.1041 - val_accuracy: 0.9604 - val_loss: 0.1177\n",
            "Epoch 10/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 656ms/step - accuracy: 0.9698 - loss: 0.0827 - val_accuracy: 0.9505 - val_loss: 0.1201\n",
            "Epoch 11/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 720ms/step - accuracy: 0.9723 - loss: 0.0806 - val_accuracy: 0.9356 - val_loss: 0.1911\n",
            "Epoch 12/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 657ms/step - accuracy: 0.9716 - loss: 0.0822 - val_accuracy: 0.9059 - val_loss: 0.2614\n",
            "Epoch 13/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 699ms/step - accuracy: 0.9629 - loss: 0.0860 - val_accuracy: 0.9604 - val_loss: 0.1307\n",
            "Epoch 14/80\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 655ms/step - accuracy: 0.9774 - loss: 0.0719 - val_accuracy: 0.9505 - val_loss: 0.1416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/best_model.keras /content/drive/MyDrive/VIPERC/"
      ],
      "metadata": {
        "id": "ciel98T6Wm3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best model\n",
        "from tensorflow.keras.models import load_model\n",
        "best_model = load_model('best_model.keras')"
      ],
      "metadata": {
        "id": "PnARkl93K11I"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Đánh giá trên test set\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "test_loss, test_accuracy = best_model.evaluate(test_generator)\n",
        "print(f'\\nTest Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
        "\n",
        "# Lấy nhãn class\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "predictions = best_model.predict(test_generator)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = test_generator.classes\n",
        "\n",
        "# Metrics\n",
        "accuracy = accuracy_score(true_classes, predicted_classes)\n",
        "precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
        "recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
        "f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
        "\n",
        "print('Accuracy:', accuracy * 100)\n",
        "print('Precision:', precision * 100)\n",
        "print('Recall:', recall * 100)\n",
        "print('F1 Score:', f1* 100)\n",
        "\n",
        "print('\\nClassification Report:')\n",
        "print(classification_report(true_classes, predicted_classes, target_names=class_labels, digits=4))\n",
        "\n",
        "# Accuracy theo từng class\n",
        "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
        "\n",
        "print('\\nAccuracy for each class:')\n",
        "for class_name, class_accuracy in zip(class_labels, class_accuracies):\n",
        "    print(f'{class_name}: {class_accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RC2db3Dvuso",
        "outputId": "369af67f-9a29-43f4-9756-023b820d687f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2s/step - accuracy: 0.9573 - loss: 0.1102\n",
            "\n",
            "Test Loss: 0.1230\n",
            "Test Accuracy: 95.61%\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step\n",
            "Accuracy: 95.60975609756098\n",
            "Precision: 95.69044871847179\n",
            "Recall: 95.60975609756098\n",
            "F1 Score: 95.59657660681322\n",
            "\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            " bong-troc-son     0.9600    0.9412    0.9505        51\n",
            "day-cap-ri-set     0.9180    0.9825    0.9492        57\n",
            "        ri-set     0.9592    0.9038    0.9307        52\n",
            "       vet-nut     1.0000    1.0000    1.0000        45\n",
            "\n",
            "      accuracy                         0.9561       205\n",
            "     macro avg     0.9593    0.9569    0.9576       205\n",
            "  weighted avg     0.9569    0.9561    0.9560       205\n",
            "\n",
            "\n",
            "Accuracy for each class:\n",
            "bong-troc-son: 0.94\n",
            "day-cap-ri-set: 0.98\n",
            "ri-set: 0.90\n",
            "vet-nut: 1.00\n"
          ]
        }
      ]
    }
  ]
}