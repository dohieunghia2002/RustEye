{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "shADrZ_kWJe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9494d12f-067b-4ea6-a913-2d603c5e3704"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/RUSTEYE/dataset_cnn_v2.zip"
      ],
      "metadata": {
        "id": "h4sBLblm9z-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k3GbZIAzUqPh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (128, 128)\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 80"
      ],
      "metadata": {
        "id": "FvFKwzZ_Uyz6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/dataset_cnn_v2/train'\n",
        "val_dir   = '/content/dataset_cnn_v2/valid'\n",
        "test_dir = '/content/dataset_cnn_v2/test'\n",
        "\n",
        "# Data augmentation cho train\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Train generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Validation generator\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Test generator\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "g7DqWMXJU4MM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6250488-bd47-4919-999d-8663aa359020"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 945 images belonging to 4 classes.\n",
            "Found 202 images belonging to 4 classes.\n",
            "Found 205 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Thêm các layer phía trên\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "C8-LD-FWU8ST",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "100d9a48-6609-4b43-bb43-2a90d9a330f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "_AS9a9h-VFTU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min', restore_best_weights=True)"
      ],
      "metadata": {
        "id": "xQCN6HYCVLlx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "5X7pIPN1VYCl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "724f5820-c7a7-4156-f801-cfefdf4b35ce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 577ms/step - accuracy: 0.4623 - loss: 3.8552 - val_accuracy: 0.8020 - val_loss: 0.5739\n",
            "Epoch 2/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 238ms/step - accuracy: 0.7831 - loss: 0.5533 - val_accuracy: 0.8317 - val_loss: 0.4416\n",
            "Epoch 3/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 222ms/step - accuracy: 0.7834 - loss: 0.5733 - val_accuracy: 0.7871 - val_loss: 0.6245\n",
            "Epoch 4/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 233ms/step - accuracy: 0.8203 - loss: 0.4839 - val_accuracy: 0.8168 - val_loss: 0.4535\n",
            "Epoch 5/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 254ms/step - accuracy: 0.8008 - loss: 0.5113 - val_accuracy: 0.8911 - val_loss: 0.3844\n",
            "Epoch 6/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 218ms/step - accuracy: 0.8351 - loss: 0.3907 - val_accuracy: 0.7970 - val_loss: 0.4238\n",
            "Epoch 7/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 219ms/step - accuracy: 0.8374 - loss: 0.3868 - val_accuracy: 0.8465 - val_loss: 0.3970\n",
            "Epoch 8/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 237ms/step - accuracy: 0.8612 - loss: 0.3706 - val_accuracy: 0.8861 - val_loss: 0.3787\n",
            "Epoch 9/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 235ms/step - accuracy: 0.8785 - loss: 0.3556 - val_accuracy: 0.8861 - val_loss: 0.3273\n",
            "Epoch 10/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 217ms/step - accuracy: 0.8658 - loss: 0.3538 - val_accuracy: 0.8515 - val_loss: 0.4619\n",
            "Epoch 11/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 220ms/step - accuracy: 0.8635 - loss: 0.3250 - val_accuracy: 0.8911 - val_loss: 0.3370\n",
            "Epoch 12/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 253ms/step - accuracy: 0.8823 - loss: 0.3086 - val_accuracy: 0.8614 - val_loss: 0.3450\n",
            "Epoch 13/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 216ms/step - accuracy: 0.8833 - loss: 0.3188 - val_accuracy: 0.7970 - val_loss: 0.6078\n",
            "Epoch 14/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 219ms/step - accuracy: 0.8710 - loss: 0.3891 - val_accuracy: 0.8812 - val_loss: 0.3449\n",
            "Epoch 15/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 218ms/step - accuracy: 0.8872 - loss: 0.2855 - val_accuracy: 0.8861 - val_loss: 0.3778\n",
            "Epoch 16/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 217ms/step - accuracy: 0.9059 - loss: 0.2538 - val_accuracy: 0.9059 - val_loss: 0.3516\n",
            "Epoch 17/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 218ms/step - accuracy: 0.9002 - loss: 0.2528 - val_accuracy: 0.8366 - val_loss: 0.4709\n",
            "Epoch 18/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 216ms/step - accuracy: 0.8526 - loss: 0.3148 - val_accuracy: 0.8911 - val_loss: 0.3542\n",
            "Epoch 19/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 217ms/step - accuracy: 0.8958 - loss: 0.2831 - val_accuracy: 0.9010 - val_loss: 0.3560\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best model\n",
        "from tensorflow.keras.models import load_model\n",
        "best_model = load_model('best_model.keras')"
      ],
      "metadata": {
        "id": "PnARkl93K11I"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Đánh giá trên test set\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "test_loss, test_accuracy = best_model.evaluate(test_generator)\n",
        "print(f'\\nTest Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
        "\n",
        "# Lấy nhãn class\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "predictions = best_model.predict(test_generator)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = test_generator.classes\n",
        "\n",
        "# Metrics\n",
        "accuracy = accuracy_score(true_classes, predicted_classes)\n",
        "precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
        "recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
        "f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
        "\n",
        "print('Accuracy:', accuracy * 100)\n",
        "print('Precision:', precision * 100)\n",
        "print('Recall:', recall * 100)\n",
        "print('F1 Score:', f1* 100)\n",
        "\n",
        "print('\\nClassification Report:')\n",
        "print(classification_report(true_classes, predicted_classes, target_names=class_labels, digits=4))\n",
        "\n",
        "# Accuracy theo từng class\n",
        "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
        "\n",
        "print('\\nAccuracy for each class:')\n",
        "for class_name, class_accuracy in zip(class_labels, class_accuracies):\n",
        "    print(f'{class_name}: {class_accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RC2db3Dvuso",
        "outputId": "85296209-0ba9-496f-c91e-92dfe2a3f703"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 540ms/step - accuracy: 0.8652 - loss: 0.4180\n",
            "\n",
            "Test Loss: 0.4377\n",
            "Test Accuracy: 85.85%\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 609ms/step\n",
            "Accuracy: 85.85365853658537\n",
            "Precision: 87.09901908801697\n",
            "Recall: 85.85365853658537\n",
            "F1 Score: 85.79608778874913\n",
            "\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            " bong-troc-son     0.7188    0.9020    0.8000        51\n",
            "day-cap-ri-set     0.8750    0.8596    0.8673        57\n",
            "        ri-set     0.9231    0.6923    0.7912        52\n",
            "       vet-nut     0.9783    1.0000    0.9890        45\n",
            "\n",
            "      accuracy                         0.8585       205\n",
            "     macro avg     0.8738    0.8635    0.8619       205\n",
            "  weighted avg     0.8710    0.8585    0.8580       205\n",
            "\n",
            "\n",
            "Accuracy for each class:\n",
            "bong-troc-son: 0.90\n",
            "day-cap-ri-set: 0.86\n",
            "ri-set: 0.69\n",
            "vet-nut: 1.00\n"
          ]
        }
      ]
    }
  ]
}