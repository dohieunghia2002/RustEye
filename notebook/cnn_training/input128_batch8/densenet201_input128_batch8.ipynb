{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "shADrZ_kWJe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9494d12f-067b-4ea6-a913-2d603c5e3704"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/RUSTEYE/dataset_cnn_v2.zip"
      ],
      "metadata": {
        "id": "h4sBLblm9z-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k3GbZIAzUqPh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (128, 128)\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 80"
      ],
      "metadata": {
        "id": "FvFKwzZ_Uyz6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/dataset_cnn_v2/train'\n",
        "val_dir   = '/content/dataset_cnn_v2/valid'\n",
        "test_dir = '/content/dataset_cnn_v2/test'\n",
        "\n",
        "# Data augmentation cho train\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Train generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Validation generator\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Test generator\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "g7DqWMXJU4MM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "556981de-9ac9-4c52-df18-65c7beb9e850"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 945 images belonging to 4 classes.\n",
            "Found 202 images belonging to 4 classes.\n",
            "Found 205 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Thêm các layer phía trên\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "C8-LD-FWU8ST"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "_AS9a9h-VFTU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, mode='min', restore_best_weights=True)"
      ],
      "metadata": {
        "id": "xQCN6HYCVLlx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "5X7pIPN1VYCl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3c31dca-bacf-406b-bc4a-0b0d1d0d2bd7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 689ms/step - accuracy: 0.6636 - loss: 1.3629 - val_accuracy: 0.8515 - val_loss: 0.3433\n",
            "Epoch 2/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 144ms/step - accuracy: 0.8748 - loss: 0.3428 - val_accuracy: 0.9307 - val_loss: 0.2007\n",
            "Epoch 3/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 129ms/step - accuracy: 0.9025 - loss: 0.2536 - val_accuracy: 0.9109 - val_loss: 0.2481\n",
            "Epoch 4/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 155ms/step - accuracy: 0.9236 - loss: 0.2262 - val_accuracy: 0.9505 - val_loss: 0.1626\n",
            "Epoch 5/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 126ms/step - accuracy: 0.9460 - loss: 0.1560 - val_accuracy: 0.9406 - val_loss: 0.1941\n",
            "Epoch 6/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 124ms/step - accuracy: 0.9688 - loss: 0.1296 - val_accuracy: 0.9455 - val_loss: 0.2525\n",
            "Epoch 7/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 149ms/step - accuracy: 0.9419 - loss: 0.1660 - val_accuracy: 0.9356 - val_loss: 0.1497\n",
            "Epoch 8/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 153ms/step - accuracy: 0.9613 - loss: 0.1052 - val_accuracy: 0.9356 - val_loss: 0.1433\n",
            "Epoch 9/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 125ms/step - accuracy: 0.9554 - loss: 0.1185 - val_accuracy: 0.9059 - val_loss: 0.2806\n",
            "Epoch 10/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 144ms/step - accuracy: 0.9467 - loss: 0.1187 - val_accuracy: 0.9604 - val_loss: 0.1167\n",
            "Epoch 11/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 125ms/step - accuracy: 0.9725 - loss: 0.0849 - val_accuracy: 0.9356 - val_loss: 0.1976\n",
            "Epoch 12/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 124ms/step - accuracy: 0.9613 - loss: 0.1083 - val_accuracy: 0.9653 - val_loss: 0.1296\n",
            "Epoch 13/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 130ms/step - accuracy: 0.9595 - loss: 0.1154 - val_accuracy: 0.9604 - val_loss: 0.1307\n",
            "Epoch 14/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 147ms/step - accuracy: 0.9733 - loss: 0.0917 - val_accuracy: 0.9653 - val_loss: 0.1068\n",
            "Epoch 15/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 127ms/step - accuracy: 0.9669 - loss: 0.1137 - val_accuracy: 0.9356 - val_loss: 0.1940\n",
            "Epoch 16/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 130ms/step - accuracy: 0.9843 - loss: 0.0553 - val_accuracy: 0.9455 - val_loss: 0.2320\n",
            "Epoch 17/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - accuracy: 0.9596 - loss: 0.1168 - val_accuracy: 0.9406 - val_loss: 0.1790\n",
            "Epoch 18/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 126ms/step - accuracy: 0.9740 - loss: 0.0639 - val_accuracy: 0.9158 - val_loss: 0.2355\n",
            "Epoch 19/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 127ms/step - accuracy: 0.9589 - loss: 0.0989 - val_accuracy: 0.9505 - val_loss: 0.1731\n",
            "Epoch 20/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 124ms/step - accuracy: 0.9788 - loss: 0.0648 - val_accuracy: 0.9406 - val_loss: 0.2426\n",
            "Epoch 21/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 125ms/step - accuracy: 0.9643 - loss: 0.1054 - val_accuracy: 0.9455 - val_loss: 0.2235\n",
            "Epoch 22/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 125ms/step - accuracy: 0.9740 - loss: 0.0901 - val_accuracy: 0.9406 - val_loss: 0.2788\n",
            "Epoch 23/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 127ms/step - accuracy: 0.9768 - loss: 0.0612 - val_accuracy: 0.9208 - val_loss: 0.2696\n",
            "Epoch 24/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - accuracy: 0.9736 - loss: 0.0662 - val_accuracy: 0.9554 - val_loss: 0.1634\n",
            "Epoch 25/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 126ms/step - accuracy: 0.9790 - loss: 0.0485 - val_accuracy: 0.9554 - val_loss: 0.1704\n",
            "Epoch 26/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 124ms/step - accuracy: 0.9766 - loss: 0.0741 - val_accuracy: 0.9455 - val_loss: 0.1392\n",
            "Epoch 27/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 124ms/step - accuracy: 0.9953 - loss: 0.0197 - val_accuracy: 0.9604 - val_loss: 0.1521\n",
            "Epoch 28/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 131ms/step - accuracy: 0.9690 - loss: 0.0793 - val_accuracy: 0.9505 - val_loss: 0.1644\n",
            "Epoch 29/80\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 128ms/step - accuracy: 0.9726 - loss: 0.0801 - val_accuracy: 0.9455 - val_loss: 0.3118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best model\n",
        "from tensorflow.keras.models import load_model\n",
        "best_model = load_model('best_model.keras')"
      ],
      "metadata": {
        "id": "PnARkl93K11I"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Đánh giá trên test set\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "test_loss, test_accuracy = best_model.evaluate(test_generator)\n",
        "print(f'\\nTest Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
        "\n",
        "# Lấy nhãn class\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "predictions = best_model.predict(test_generator)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = test_generator.classes\n",
        "\n",
        "# Metrics\n",
        "accuracy = accuracy_score(true_classes, predicted_classes)\n",
        "precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
        "recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
        "f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
        "\n",
        "print('Accuracy:', accuracy * 100)\n",
        "print('Precision:', precision * 100)\n",
        "print('Recall:', recall * 100)\n",
        "print('F1 Score:', f1* 100)\n",
        "\n",
        "print('\\nClassification Report:')\n",
        "print(classification_report(true_classes, predicted_classes, target_names=class_labels, digits=4))\n",
        "\n",
        "# Accuracy theo từng class\n",
        "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
        "\n",
        "print('\\nAccuracy for each class:')\n",
        "for class_name, class_accuracy in zip(class_labels, class_accuracies):\n",
        "    print(f'{class_name}: {class_accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RC2db3Dvuso",
        "outputId": "0f6c8fc9-93dc-41e1-8c48-b94d9b29ae42"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 941ms/step - accuracy: 0.9724 - loss: 0.0848\n",
            "\n",
            "Test Loss: 0.1179\n",
            "Test Accuracy: 96.10%\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 979ms/step\n",
            "Accuracy: 96.09756097560975\n",
            "Precision: 96.42276422764228\n",
            "Recall: 96.09756097560975\n",
            "F1 Score: 96.10552513688401\n",
            "\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            " bong-troc-son     0.9804    0.9804    0.9804        51\n",
            "day-cap-ri-set     0.8889    0.9825    0.9333        57\n",
            "        ri-set     1.0000    0.8846    0.9388        52\n",
            "       vet-nut     1.0000    1.0000    1.0000        45\n",
            "\n",
            "      accuracy                         0.9610       205\n",
            "     macro avg     0.9673    0.9619    0.9631       205\n",
            "  weighted avg     0.9642    0.9610    0.9611       205\n",
            "\n",
            "\n",
            "Accuracy for each class:\n",
            "bong-troc-son: 0.98\n",
            "day-cap-ri-set: 0.98\n",
            "ri-set: 0.88\n",
            "vet-nut: 1.00\n"
          ]
        }
      ]
    }
  ]
}